{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "# import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tensorflow as tf\n",
    "# from transformers import TFBertModel\n",
    "# from transformers import BertTokenizer\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BERT model selected           : https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1\n",
      "Preprocess model auto-selected: https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\n"
     ]
    }
   ],
   "source": [
    "map_name_to_handle = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_L-12_H-768_A-12/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-2_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-6_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-8_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-10_H-768_A-12/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-128_A-2/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-256_A-4/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-512_A-8/1',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_base/2',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/google/electra_small/2',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/google/electra_base/2',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/google/experts/bert/pubmed/2',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/google/experts/bert/wiki_books/2',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/talkheads_ggelu_bert_en_base/1',\n",
    "}\n",
    "\n",
    "map_model_to_preprocess = {\n",
    "    'bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_en_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_cased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-2_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-4_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-6_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-8_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-10_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-128_A-2':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-256_A-4':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-512_A-8':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'small_bert/bert_en_uncased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'bert_multi_cased_L-12_H-768_A-12':\n",
    "        'https://tfhub.dev/tensorflow/bert_multi_cased_preprocess/3',\n",
    "    'albert_en_base':\n",
    "        'https://tfhub.dev/tensorflow/albert_en_preprocess/3',\n",
    "    'electra_small':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'electra_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_pubmed':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'experts_wiki_books':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "    'talking-heads_base':\n",
    "        'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3',\n",
    "}\n",
    "\n",
    "bert_model_name = 'small_bert/bert_en_uncased_L-12_H-768_A-12' \n",
    "\n",
    "tfhub_handle_encoder = map_name_to_handle[bert_model_name]\n",
    "tfhub_handle_preprocess = map_model_to_preprocess[bert_model_name]\n",
    "\n",
    "print(f'BERT model selected           : {tfhub_handle_encoder}')\n",
    "print(f'Preprocess model auto-selected: {tfhub_handle_preprocess}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_encoder = hub.KerasLayer(tfhub_handle_encoder)\n",
    "bert_preprocess = hub.KerasLayer(tfhub_handle_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'keras_layer', 'trainable': False, 'dtype': 'float32', 'handle': 'https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-12_H-768_A-12/1'}\n",
      "{'name': 'keras_layer_1', 'trainable': False, 'dtype': 'float32', 'handle': 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'}\n"
     ]
    }
   ],
   "source": [
    "print(bert_encoder.get_config())\n",
    "print(bert_preprocess.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot pickle 'tensorflow.python.client._pywrap_tf_session.TF_Operation' object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\NLP\\qa_systems\\huggingface\\nlp_course\\dataset_loading\\bert_transformer1.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DANNY/Desktop/machtensor/NLP/qa_systems/huggingface/nlp_course/dataset_loading/bert_transformer1.ipynb#X50sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m bert_preprocess_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mtokenizers/tfhub/bert_preprocess.pkl\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DANNY/Desktop/machtensor/NLP/qa_systems/huggingface/nlp_course/dataset_loading/bert_transformer1.ipynb#X50sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# pickle.dump(bert_encoder, open(bert_encoder_path, 'wb'))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DANNY/Desktop/machtensor/NLP/qa_systems/huggingface/nlp_course/dataset_loading/bert_transformer1.ipynb#X50sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# pickle.dump(bert_preprocess, open(bert_preprocess_path, 'wb'))\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DANNY/Desktop/machtensor/NLP/qa_systems/huggingface/nlp_course/dataset_loading/bert_transformer1.ipynb#X50sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/DANNY/Desktop/machtensor/NLP/qa_systems/huggingface/nlp_course/dataset_loading/bert_transformer1.ipynb#X50sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# bert_encoder = pickle.load(open(bert_encoder_path,'rb'))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DANNY/Desktop/machtensor/NLP/qa_systems/huggingface/nlp_course/dataset_loading/bert_transformer1.ipynb#X50sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# bert_preprocess = pickle.load(open(bert_preprocess_path,'rb'))\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/DANNY/Desktop/machtensor/NLP/qa_systems/huggingface/nlp_course/dataset_loading/bert_transformer1.ipynb#X50sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m joblib\u001b[39m.\u001b[39;49mdump(bert_encoder, bert_encoder_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DANNY/Desktop/machtensor/NLP/qa_systems/huggingface/nlp_course/dataset_loading/bert_transformer1.ipynb#X50sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m joblib\u001b[39m.\u001b[39mdump(bert_preprocess, bert_preprocess_path)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/DANNY/Desktop/machtensor/NLP/qa_systems/huggingface/nlp_course/dataset_loading/bert_transformer1.ipynb#X50sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m bert_encoder \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39mload(bert_encoder_path)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:553\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[0;32m    551\u001b[0m \u001b[39melif\u001b[39;00m is_filename:\n\u001b[0;32m    552\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(filename, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m--> 553\u001b[0m         NumpyPickler(f, protocol\u001b[39m=\u001b[39;49mprotocol)\u001b[39m.\u001b[39;49mdump(value)\n\u001b[0;32m    554\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    555\u001b[0m     NumpyPickler(filename, protocol\u001b[39m=\u001b[39mprotocol)\u001b[39m.\u001b[39mdump(value)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:487\u001b[0m, in \u001b[0;36m_Pickler.dump\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m4\u001b[39m:\n\u001b[0;32m    486\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mstart_framing()\n\u001b[1;32m--> 487\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave(obj)\n\u001b[0;32m    488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(STOP)\n\u001b[0;32m    489\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframer\u001b[39m.\u001b[39mend_framing()\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1212\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1210\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1212\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1213\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:886\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    885\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[1;32m--> 886\u001b[0m         save(element)\n\u001b[0;32m    887\u001b[0m     \u001b[39m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[0;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1212\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1210\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1212\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1213\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:1002\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m   1000\u001b[0m     k, v \u001b[39m=\u001b[39m tmp[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1001\u001b[0m     save(k)\n\u001b[1;32m-> 1002\u001b[0m     save(v)\n\u001b[0;32m   1003\u001b[0m     write(SETITEM)\n\u001b[0;32m   1004\u001b[0m \u001b[39m# else tmp is empty, and we're done\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1212\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1210\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1212\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1213\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:996\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    994\u001b[0m write(MARK)\n\u001b[0;32m    995\u001b[0m \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m--> 996\u001b[0m     save(k)\n\u001b[0;32m    997\u001b[0m     save(v)\n\u001b[0;32m    998\u001b[0m write(SETITEMS)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:886\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    885\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[1;32m--> 886\u001b[0m         save(element)\n\u001b[0;32m    887\u001b[0m     \u001b[39m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[0;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1212\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1210\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1212\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1213\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:1002\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m   1000\u001b[0m     k, v \u001b[39m=\u001b[39m tmp[\u001b[39m0\u001b[39m]\n\u001b[0;32m   1001\u001b[0m     save(k)\n\u001b[1;32m-> 1002\u001b[0m     save(v)\n\u001b[0;32m   1003\u001b[0m     write(SETITEM)\n\u001b[0;32m   1004\u001b[0m \u001b[39m# else tmp is empty, and we're done\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1212\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1210\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1212\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1213\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:931\u001b[0m, in \u001b[0;36m_Pickler.save_list\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m LIST)\n\u001b[0;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 931\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_appends(obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:955\u001b[0m, in \u001b[0;36m_Pickler._batch_appends\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    953\u001b[0m     write(MARK)\n\u001b[0;32m    954\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m--> 955\u001b[0m         save(x)\n\u001b[0;32m    956\u001b[0m     write(APPENDS)\n\u001b[0;32m    957\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (1 times), _Pickler.save at line 560 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:886\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    885\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[1;32m--> 886\u001b[0m         save(element)\n\u001b[0;32m    887\u001b[0m     \u001b[39m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[0;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (1 times), _Pickler.save at line 560 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1212\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1210\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1212\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1213\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (3 times), _Pickler.save at line 560 (2 times), _Pickler._batch_setitems at line 997 (1 times), _Pickler.save at line 603 (1 times), _Pickler.save_dict at line 971 (1 times), save_module_dict at line 1212 (1 times), _Pickler.save_reduce at line 717 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:931\u001b[0m, in \u001b[0;36m_Pickler.save_list\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m LIST)\n\u001b[0;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 931\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_appends(obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:955\u001b[0m, in \u001b[0;36m_Pickler._batch_appends\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    953\u001b[0m     write(MARK)\n\u001b[0;32m    954\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m--> 955\u001b[0m         save(x)\n\u001b[0;32m    956\u001b[0m     write(APPENDS)\n\u001b[0;32m    957\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (2 times), _Pickler.save at line 603 (1 times), _Pickler.save at line 560 (1 times), _Pickler.save_reduce at line 717 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:886\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    885\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[1;32m--> 886\u001b[0m         save(element)\n\u001b[0;32m    887\u001b[0m     \u001b[39m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[0;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (10 times), _Pickler.save at line 560 (7 times), _Pickler._batch_setitems at line 997 (4 times), _Pickler.save_dict at line 971 (4 times), save_module_dict at line 1212 (4 times), _Pickler.save at line 603 (3 times), _Pickler.save_reduce at line 717 (3 times), _Pickler._batch_appends at line 955 (1 times), _Pickler.save_list at line 931 (1 times), _Pickler.save_tuple at line 886 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:931\u001b[0m, in \u001b[0;36m_Pickler.save_list\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    928\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m LIST)\n\u001b[0;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 931\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_appends(obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:955\u001b[0m, in \u001b[0;36m_Pickler._batch_appends\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    953\u001b[0m     write(MARK)\n\u001b[0;32m    954\u001b[0m     \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m tmp:\n\u001b[1;32m--> 955\u001b[0m         save(x)\n\u001b[0;32m    956\u001b[0m     write(APPENDS)\n\u001b[0;32m    957\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (2 times), _Pickler.save at line 603 (1 times), _Pickler.save at line 560 (1 times), _Pickler.save_reduce at line 717 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:886\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    885\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[1;32m--> 886\u001b[0m         save(element)\n\u001b[0;32m    887\u001b[0m     \u001b[39m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[0;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (2 times), _Pickler._batch_setitems at line 997 (1 times), _Pickler.save at line 560 (1 times), _Pickler.save_dict at line 971 (1 times), save_module_dict at line 1212 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (1 times), _Pickler.save at line 560 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1212\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1210\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1212\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1213\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1965\u001b[0m, in \u001b[0;36msave_function\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1962\u001b[0m \u001b[39mif\u001b[39;00m state_dict:\n\u001b[0;32m   1963\u001b[0m     state \u001b[39m=\u001b[39m state, state_dict\n\u001b[1;32m-> 1965\u001b[0m _save_with_postproc(pickler, (_create_function, (\n\u001b[0;32m   1966\u001b[0m         obj\u001b[39m.\u001b[39;49m\u001b[39m__code__\u001b[39;49m, globs, obj\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m, obj\u001b[39m.\u001b[39;49m\u001b[39m__defaults__\u001b[39;49m,\n\u001b[0;32m   1967\u001b[0m         closure\n\u001b[0;32m   1968\u001b[0m ), state), obj\u001b[39m=\u001b[39;49mobj, postproc_list\u001b[39m=\u001b[39;49mpostproc_list)\n\u001b[0;32m   1970\u001b[0m \u001b[39m# Lift closure cell update to earliest function (#458)\u001b[39;00m\n\u001b[0;32m   1971\u001b[0m \u001b[39mif\u001b[39;00m _postproc:\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1093\u001b[0m, in \u001b[0;36m_save_with_postproc\u001b[1;34m(pickler, reduction, is_pickler_dill, obj, postproc_list)\u001b[0m\n\u001b[0;32m   1090\u001b[0m     pickler\u001b[39m.\u001b[39m_postproc[\u001b[39mid\u001b[39m(obj)] \u001b[39m=\u001b[39m postproc_list\n\u001b[0;32m   1092\u001b[0m \u001b[39m# TODO: Use state_setter in Python 3.8 to allow for faster cPickle implementations\u001b[39;00m\n\u001b[1;32m-> 1093\u001b[0m pickler\u001b[39m.\u001b[39;49msave_reduce(\u001b[39m*\u001b[39;49mreduction, obj\u001b[39m=\u001b[39;49mobj)\n\u001b[0;32m   1095\u001b[0m \u001b[39mif\u001b[39;00m is_pickler_dill:\n\u001b[0;32m   1096\u001b[0m     \u001b[39m# pickler.x -= 1\u001b[39;00m\n\u001b[0;32m   1097\u001b[0m     \u001b[39m# print(pickler.x*' ', 'pop', obj, id(obj))\u001b[39;00m\n\u001b[0;32m   1098\u001b[0m     postproc \u001b[39m=\u001b[39m pickler\u001b[39m.\u001b[39m_postproc\u001b[39m.\u001b[39mpop(\u001b[39mid\u001b[39m(obj))\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:692\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     save(func)\n\u001b[1;32m--> 692\u001b[0m     save(args)\n\u001b[0;32m    693\u001b[0m     write(REDUCE)\n\u001b[0;32m    695\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    696\u001b[0m     \u001b[39m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[0;32m    697\u001b[0m     \u001b[39m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[0;32m    698\u001b[0m     \u001b[39m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:901\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    899\u001b[0m write(MARK)\n\u001b[0;32m    900\u001b[0m \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[1;32m--> 901\u001b[0m     save(element)\n\u001b[0;32m    903\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n\u001b[0;32m    904\u001b[0m     \u001b[39m# Subtle.  d was not in memo when we entered save_tuple(), so\u001b[39;00m\n\u001b[0;32m    905\u001b[0m     \u001b[39m# the process of saving the tuple's elements must have saved\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m     \u001b[39m# could have been done in the \"for element\" loop instead, but\u001b[39;00m\n\u001b[0;32m    910\u001b[0m     \u001b[39m# recursive tuples are a rare thing.\u001b[39;00m\n\u001b[0;32m    911\u001b[0m     get \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget(memo[\u001b[39mid\u001b[39m(obj)][\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:886\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    885\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[1;32m--> 886\u001b[0m         save(element)\n\u001b[0;32m    887\u001b[0m     \u001b[39m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[0;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1520\u001b[0m, in \u001b[0;36msave_cell\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1518\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m   1519\u001b[0m logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39mCe1: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m, obj)\n\u001b[1;32m-> 1520\u001b[0m pickler\u001b[39m.\u001b[39;49msave_reduce(_create_cell, (f,), obj\u001b[39m=\u001b[39;49mobj)\n\u001b[0;32m   1521\u001b[0m logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# Ce1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1522\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:692\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    691\u001b[0m     save(func)\n\u001b[1;32m--> 692\u001b[0m     save(args)\n\u001b[0;32m    693\u001b[0m     write(REDUCE)\n\u001b[0;32m    695\u001b[0m \u001b[39mif\u001b[39;00m obj \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    696\u001b[0m     \u001b[39m# If the object is already in the memo, this means it is\u001b[39;00m\n\u001b[0;32m    697\u001b[0m     \u001b[39m# recursive. In this case, throw away everything we put on the\u001b[39;00m\n\u001b[0;32m    698\u001b[0m     \u001b[39m# stack, and fetch the object back from the memo.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:886\u001b[0m, in \u001b[0;36m_Pickler.save_tuple\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    884\u001b[0m \u001b[39mif\u001b[39;00m n \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m3\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mproto \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m    885\u001b[0m     \u001b[39mfor\u001b[39;00m element \u001b[39min\u001b[39;00m obj:\n\u001b[1;32m--> 886\u001b[0m         save(element)\n\u001b[0;32m    887\u001b[0m     \u001b[39m# Subtle.  Same as in the big comment below.\u001b[39;00m\n\u001b[0;32m    888\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mid\u001b[39m(obj) \u001b[39min\u001b[39;00m memo:\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1212\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1210\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1212\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1213\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (1 times), _Pickler.save at line 560 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1212\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1210\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1212\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1213\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (3 times), _Pickler._batch_setitems at line 997 (2 times), _Pickler.save at line 560 (2 times), _Pickler.save_dict at line 971 (2 times), save_module_dict at line 1212 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:603\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    599\u001b[0m     \u001b[39mraise\u001b[39;00m PicklingError(\u001b[39m\"\u001b[39m\u001b[39mTuple returned by \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m must have \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    600\u001b[0m                         \u001b[39m\"\u001b[39m\u001b[39mtwo to six elements\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m reduce)\n\u001b[0;32m    602\u001b[0m \u001b[39m# Save the reduce() output and finally memoize the object\u001b[39;00m\n\u001b[1;32m--> 603\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_reduce(obj\u001b[39m=\u001b[39;49mobj, \u001b[39m*\u001b[39;49mrv)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:717\u001b[0m, in \u001b[0;36m_Pickler.save_reduce\u001b[1;34m(self, func, args, state, listitems, dictitems, state_setter, obj)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[39mif\u001b[39;00m state \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    716\u001b[0m     \u001b[39mif\u001b[39;00m state_setter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 717\u001b[0m         save(state)\n\u001b[0;32m    718\u001b[0m         write(BUILD)\n\u001b[0;32m    719\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m         \u001b[39m# If a state_setter is specified, call it instead of load_build\u001b[39;00m\n\u001b[0;32m    721\u001b[0m         \u001b[39m# to update obj's with its previous state.\u001b[39;00m\n\u001b[0;32m    722\u001b[0m         \u001b[39m# First, push state_setter and its tuple of expected arguments\u001b[39;00m\n\u001b[0;32m    723\u001b[0m         \u001b[39m# (obj, state) onto the stack.\u001b[39;00m\n",
      "    \u001b[1;31m[... skipping similar frames: NumpyPickler.save at line 355 (1 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:560\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    558\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch\u001b[39m.\u001b[39mget(t)\n\u001b[0;32m    559\u001b[0m \u001b[39mif\u001b[39;00m f \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 560\u001b[0m     f(\u001b[39mself\u001b[39;49m, obj)  \u001b[39m# Call unbound method with explicit self\u001b[39;00m\n\u001b[0;32m    561\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    563\u001b[0m \u001b[39m# Check private dispatch table if any, or else\u001b[39;00m\n\u001b[0;32m    564\u001b[0m \u001b[39m# copyreg.dispatch_table\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\dill\\_dill.py:1212\u001b[0m, in \u001b[0;36msave_module_dict\u001b[1;34m(pickler, obj)\u001b[0m\n\u001b[0;32m   1209\u001b[0m     \u001b[39mif\u001b[39;00m is_dill(pickler, child\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m) \u001b[39mand\u001b[39;00m pickler\u001b[39m.\u001b[39m_session:\n\u001b[0;32m   1210\u001b[0m         \u001b[39m# we only care about session the first pass thru\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         pickler\u001b[39m.\u001b[39m_first_pass \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m-> 1212\u001b[0m     StockPickler\u001b[39m.\u001b[39;49msave_dict(pickler, obj)\n\u001b[0;32m   1213\u001b[0m     logger\u001b[39m.\u001b[39mtrace(pickler, \u001b[39m\"\u001b[39m\u001b[39m# D2\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1214\u001b[0m \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:971\u001b[0m, in \u001b[0;36m_Pickler.save_dict\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrite(MARK \u001b[39m+\u001b[39m DICT)\n\u001b[0;32m    970\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemoize(obj)\n\u001b[1;32m--> 971\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_setitems(obj\u001b[39m.\u001b[39;49mitems())\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:997\u001b[0m, in \u001b[0;36m_Pickler._batch_setitems\u001b[1;34m(self, items)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m tmp:\n\u001b[0;32m    996\u001b[0m         save(k)\n\u001b[1;32m--> 997\u001b[0m         save(v)\n\u001b[0;32m    998\u001b[0m     write(SETITEMS)\n\u001b[0;32m    999\u001b[0m \u001b[39melif\u001b[39;00m n:\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\site-packages\\joblib\\numpy_pickle.py:355\u001b[0m, in \u001b[0;36mNumpyPickler.save\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    352\u001b[0m     wrapper\u001b[39m.\u001b[39mwrite_array(obj, \u001b[39mself\u001b[39m)\n\u001b[0;32m    353\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 355\u001b[0m \u001b[39mreturn\u001b[39;00m Pickler\u001b[39m.\u001b[39;49msave(\u001b[39mself\u001b[39;49m, obj)\n",
      "File \u001b[1;32mc:\\Users\\DANNY\\Desktop\\machtensor\\tf\\lib\\pickle.py:578\u001b[0m, in \u001b[0;36m_Pickler.save\u001b[1;34m(self, obj, save_persistent_id)\u001b[0m\n\u001b[0;32m    576\u001b[0m reduce \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m__reduce_ex__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m reduce \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 578\u001b[0m     rv \u001b[39m=\u001b[39m reduce(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mproto)\n\u001b[0;32m    579\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    580\u001b[0m     reduce \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(obj, \u001b[39m\"\u001b[39m\u001b[39m__reduce__\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: cannot pickle 'tensorflow.python.client._pywrap_tf_session.TF_Operation' object"
     ]
    }
   ],
   "source": [
    "# import pickle\n",
    "# import joblib\n",
    "# bert_encoder_path = 'models/tfhub/bert_encoder.pkl'\n",
    "# bert_preprocess_path = 'tokenizers/tfhub/bert_preprocess.pkl'\n",
    "\n",
    "# # pickle.dump(bert_encoder, open(bert_encoder_path, 'wb'))\n",
    "# # pickle.dump(bert_preprocess, open(bert_preprocess_path, 'wb'))\n",
    "\n",
    "# # bert_encoder = pickle.load(open(bert_encoder_path,'rb'))\n",
    "# # bert_preprocess = pickle.load(open(bert_preprocess_path,'rb'))\n",
    "\n",
    "# joblib.dump(bert_encoder, bert_encoder_path)\n",
    "# joblib.dump(bert_preprocess, bert_preprocess_path)\n",
    "\n",
    "# bert_encoder = joblib.load(bert_encoder_path)\n",
    "# bert_preprocess = joblib.load(bert_preprocess_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "print(tf. __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv('data/cleaned_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17340, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentiments', 'cleaned_review', 'cleaned_review_length',\n",
       "       'review_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.drop(columns=['cleaned_review_length','review_score'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking for Null Vaules and Duplicates**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiments        0\n",
       "cleaned_review    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17337, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>cleaned_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>positive</td>\n",
       "      <td>i wish would have gotten one earlier love it a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i ve learned this lesson again open the packag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neutral</td>\n",
       "      <td>it is so slow and lags find better option</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neutral</td>\n",
       "      <td>roller ball stopped working within months of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>i like the color and size but it few days out ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17335</th>\n",
       "      <td>positive</td>\n",
       "      <td>i love this speaker and love can take it anywh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17336</th>\n",
       "      <td>positive</td>\n",
       "      <td>i use it in my house easy to connect and loud ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17337</th>\n",
       "      <td>positive</td>\n",
       "      <td>the bass is good and the battery is amazing mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17338</th>\n",
       "      <td>positive</td>\n",
       "      <td>love it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17339</th>\n",
       "      <td>neutral</td>\n",
       "      <td>mono speaker</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17337 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sentiments                                     cleaned_review\n",
       "0       positive  i wish would have gotten one earlier love it a...\n",
       "1        neutral  i ve learned this lesson again open the packag...\n",
       "2        neutral          it is so slow and lags find better option\n",
       "3        neutral  roller ball stopped working within months of m...\n",
       "4        neutral  i like the color and size but it few days out ...\n",
       "...          ...                                                ...\n",
       "17335   positive  i love this speaker and love can take it anywh...\n",
       "17336   positive  i use it in my house easy to connect and loud ...\n",
       "17337   positive  the bass is good and the battery is amazing mu...\n",
       "17338   positive                                            love it\n",
       "17339    neutral                                       mono speaker\n",
       "\n",
       "[17337 rows x 2 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping was changed due to the use of a neural network architecture\n",
    "sentiment_mapping = {'negative':0,'neutral':1,'positive':2} \n",
    "df_clean['sentiment_label'] = df_clean.sentiments.map(sentiment_mapping)\n",
    "df_clean.drop(columns=['sentiments'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_review</th>\n",
       "      <th>sentiment_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i wish would have gotten one earlier love it a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i ve learned this lesson again open the packag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is so slow and lags find better option</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>roller ball stopped working within months of m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>i like the color and size but it few days out ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17335</th>\n",
       "      <td>i love this speaker and love can take it anywh...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17336</th>\n",
       "      <td>i use it in my house easy to connect and loud ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17337</th>\n",
       "      <td>the bass is good and the battery is amazing mu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17338</th>\n",
       "      <td>love it</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17339</th>\n",
       "      <td>mono speaker</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17337 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          cleaned_review  sentiment_label\n",
       "0      i wish would have gotten one earlier love it a...                2\n",
       "1      i ve learned this lesson again open the packag...                1\n",
       "2              it is so slow and lags find better option                1\n",
       "3      roller ball stopped working within months of m...                1\n",
       "4      i like the color and size but it few days out ...                1\n",
       "...                                                  ...              ...\n",
       "17335  i love this speaker and love can take it anywh...                2\n",
       "17336  i use it in my house easy to connect and loud ...                2\n",
       "17337  the bass is good and the battery is amazing mu...                2\n",
       "17338                                            love it                2\n",
       "17339                                       mono speaker                1\n",
       "\n",
       "[17337 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = tf.keras.utils.to_categorical(df_clean.sentiment_label.values, num_classes=3, dtype='int8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test= train_test_split(\n",
    "                                            df_clean['cleaned_review'],labels,test_size=.2,random_state=42, \n",
    "                                            stratify=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "# BERT LAYERS\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string,name='text')\n",
    "preprocessed_text = bert_preprocess(text_input)\n",
    "outputs = bert_encoder(preprocessed_text)\n",
    "\n",
    "# Neural network layers\n",
    "intermediate_layer1 = tf.keras.layers.Dense(512, activation=\"relu\", name=\"intermediate_layer1\")(outputs[\"pooled_output\"])\n",
    "bn_layer1 = tf.keras.layers.BatchNormalization()(intermediate_layer1)\n",
    "dropout1 = tf.keras.layers.Dropout(0.2)(bn_layer1)\n",
    "\n",
    "# intermediate_layer2 = tf.keras.layers.Dense(256, activation=\"relu\", name=\"intermediate_layer2\")(dropout1)\n",
    "# bn_layer2 = tf.keras.layers.BatchNormalization()(intermediate_layer2)\n",
    "# dropout2 = tf.keras.layers.Dropout(0.2)(bn_layer2)\n",
    "\n",
    "# intermediate_layer3 = tf.keras.layers.Dense(128, activation=\"relu\", name=\"intermediate_layer3\")(dropout2)\n",
    "# bn_layer3 = tf.keras.layers.BatchNormalization()(intermediate_layer3)\n",
    "# dropout3 = tf.keras.layers.Dropout(0.2)(bn_layer3)\n",
    "\n",
    "# intermediate_layer4 = tf.keras.layers.Dense(64, activation=\"relu\", name=\"intermediate_layer4\")(dropout3)\n",
    "# bn_layer4 = tf.keras.layers.BatchNormalization()(intermediate_layer4)\n",
    "# dropout4 = tf.keras.layers.Dropout(0.2)(bn_layer4)\n",
    "\n",
    "intermediate_layer5 = tf.keras.layers.Dense(64, activation=\"relu\", name=\"intermediate_layer5\")(dropout1)\n",
    "bn_layer5 = tf.keras.layers.BatchNormalization()(intermediate_layer5)\n",
    "dropout5 = tf.keras.layers.Dropout(0.2)(bn_layer5)\n",
    "\n",
    "# Final output\n",
    "output_layer = tf.keras.layers.Dense(3,activation=\"softmax\", name=\"output_layer\")(dropout5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Model(inputs=[text_input], outputs=output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " text (InputLayer)              [(None,)]            0           []                               \n",
      "                                                                                                  \n",
      " keras_layer_1 (KerasLayer)     {'input_word_ids':   0           ['text[0][0]']                   \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_type_ids':                                                \n",
      "                                (None, 128),                                                      \n",
      "                                 'input_mask': (Non                                               \n",
      "                                e, 128)}                                                          \n",
      "                                                                                                  \n",
      " keras_layer (KerasLayer)       {'sequence_output':  109482241   ['keras_layer_1[4][0]',          \n",
      "                                 (None, 128, 768),                'keras_layer_1[4][1]',          \n",
      "                                 'pooled_output': (               'keras_layer_1[4][2]']          \n",
      "                                None, 768),                                                       \n",
      "                                 'encoder_outputs':                                               \n",
      "                                 [(None, 128, 768),                                               \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768),                                                \n",
      "                                 (None, 128, 768)],                                               \n",
      "                                 'default': (None,                                                \n",
      "                                768)}                                                             \n",
      "                                                                                                  \n",
      " intermediate_layer1 (Dense)    (None, 512)          393728      ['keras_layer[4][13]']           \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 512)         2048        ['intermediate_layer1[0][0]']    \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 512)          0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " intermediate_layer5 (Dense)    (None, 64)           32832       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 64)          256         ['intermediate_layer5[0][0]']    \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 64)           0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " output_layer (Dense)           (None, 3)            195         ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,911,300\n",
      "Trainable params: 427,907\n",
      "Non-trainable params: 109,483,393\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the custom callback\n",
    "class MyCustomCallback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self):\n",
    "        super(MyCustomCallback, self).__init__()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if logs is not None:\n",
    "            val_loss = logs.get('val_loss') \n",
    "            loss = logs.get('loss')\n",
    "            val_acc = logs.get('val_acc') \n",
    "            acc = logs.get('acc')\n",
    "            if val_loss < 0.4:\n",
    "                print(f\"\\nValidation loss is less than 0.4. \\nStopping training.\\n\")\n",
    "                self.model.stop_training = True\n",
    "            elif (loss <0.6) and (val_loss <= loss ):\n",
    "                print(f\"\\nValidation loss is less than loss: {loss} and loss is less than 0.6\\nStopping training.\\n\")\n",
    "                self.model.stop_training = True\n",
    "            elif (val_acc >= 0.75 ) or (val_loss <= 0.55  ):\n",
    "                print(f\"\\nValidation loss is <= 0.55 or val_acc >= 0.75\\nStopping training.\\n\")\n",
    "                self.model.stop_training = True\n",
    "\n",
    "callback = MyCustomCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "class TimeCallback(tf.keras.callbacks.Callback):\n",
    "\n",
    "    def on_epoch_begin(self,epoch, logs=None):\n",
    "        print('Epoch: {}, begins at {}\\n'.format(epoch, datetime.datetime.now().time()))\n",
    "\n",
    "    def on_epoch_end(self,epoch, logs=None):\n",
    "        print('Epoch: {}, ends at {}\\n'.format(epoch, datetime.datetime.now().time()))\n",
    "\n",
    "my_timer = TimeCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning Rate Schedulers\n",
    "peak_callback = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.1,\n",
    "    patience=2,\n",
    "    mode= 'min',\n",
    "    min_lr=0.00001\n",
    ")\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch,lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "my_scheduler = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
    "# optimizer\n",
    "optimise = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "# losses\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "\n",
    "# metrics\n",
    "precision = tf.keras.metrics.Precision()\n",
    "recall = tf.keras.metrics.Recall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimise,\n",
    "            loss=loss,\n",
    "            metrics=['acc',precision,recall\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, begins at 08:44:13.243835\n",
      "\n",
      "Epoch 1/20\n",
      "694/694 [==============================] - ETA: 0s - loss: 0.6696 - acc: 0.7139 - precision: 0.7431 - recall: 0.6617Epoch: 0, ends at 09:48:21.608786\n",
      "\n",
      "694/694 [==============================] - 3848s 6s/step - loss: 0.6696 - acc: 0.7139 - precision: 0.7431 - recall: 0.6617 - val_loss: 0.6002 - val_acc: 0.7394 - val_precision: 0.7746 - val_recall: 0.6975 - lr: 0.0100\n",
      "Epoch: 1, begins at 09:48:21.628817\n",
      "\n",
      "Epoch 2/20\n",
      "694/694 [==============================] - ETA: 0s - loss: 0.6122 - acc: 0.7343 - precision: 0.7668 - recall: 0.6865\n",
      "Validation loss is <= 0.55 or val_acc >= 0.75\n",
      "Stopping training.\n",
      "\n",
      "Epoch: 1, ends at 10:42:12.313821\n",
      "\n",
      "694/694 [==============================] - 3231s 5s/step - loss: 0.6122 - acc: 0.7343 - precision: 0.7668 - recall: 0.6865 - val_loss: 0.5713 - val_acc: 0.7635 - val_precision: 0.8070 - val_recall: 0.6965 - lr: 0.0100\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "bert_model_history = model.fit(X_train,y_train,epochs=20,\n",
    "                        validation_split=.20,\n",
    "                        batch_size=16,\n",
    "                        # steps_per_epoch=5,\n",
    "                        callbacks=[callback,my_scheduler,\n",
    "                        peak_callback,my_timer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 944s 9s/step - loss: 0.5694 - acc: 0.7552 - precision: 0.7914 - recall: 0.7036\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the Test Set\n",
    "\n",
    "score = model.evaluate(X_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model Performance Charts\n",
    "\n",
    "plt.plot(bert_model_history.history['acc'])\n",
    "plt.plot(bert_model_history.history['val_acc'])\n",
    "\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training','validation'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(bert_model_history.history['loss'])\n",
    "plt.plot(bert_model_history.history['val_loss'])\n",
    "\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training','validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "# model.save(\"saved_model_hub/bert_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Classification report**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109/109 [==============================] - 959s 9s/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.54      0.27      0.36       307\n",
      "           1       0.66      0.77      0.71      1260\n",
      "           2       0.85      0.82      0.84      1901\n",
      "\n",
      "    accuracy                           0.76      3468\n",
      "   macro avg       0.68      0.62      0.64      3468\n",
      "weighted avg       0.75      0.76      0.75      3468\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classification report test data\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
    "y_true=np.argmax(y_test, axis=1)\n",
    "y_pred_test = model.predict(X_test)\n",
    "y_pred_test=np.argmax(y_pred_test, axis=1)\n",
    "sns.set_theme(style='white')\n",
    "def class_report(model,y_true,pred):\n",
    "    print(classification_report(y_true,pred))\n",
    "    cm = confusion_matrix(y_true,pred,labels=[0,1,2])\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2])\n",
    "    disp.plot()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "class_report(model,y_true,y_pred_test) \n",
    "\n",
    "# Original mapping\n",
    "# sentiment_mapping = {'negative':-1,'neutral':0,'positive':1}\n",
    "\n",
    "# New mapping\n",
    "# negative --> 0\n",
    "# neutral ---> 1\n",
    "# positive --> 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews =[ \"I can't believe I wasted my money on this keyboard and mouse\",\n",
    "            \"I really love this device\",\n",
    "            \"It's quite good, but not so great. They can do better\",\n",
    "            \"I hate this device, terrible!!!\",\n",
    "            \"Where the hell is my refund for this damn product (mouse)\",\n",
    "            \"I believe Ebay is so much better than the crap that is HERE!!!\",\n",
    "            \"worst keyboard ever\",\n",
    "            \"distasteful to the fullest!!!\",\n",
    "            \"spoilt on the first day\",\n",
    "            \"never shopping here again, waste of money\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 5s 5s/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, 0, 1, 1, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.argmax(y_pred, axis = 1)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New mapping\n",
    "# negative --> 0\n",
    "# neutral ---> 1\n",
    "# positive --> 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "- BERT is a powerful model but needs to be fine-tuned to properly make use of it, as seen from the confusion matrix, there is a lot of misclassifications. \n",
    "- A larger dataset will aid in the aid and also a balanced dataset.\n",
    "- Due to computational speed running on (CPU rather than GPU), a low epochs was used, but increasing the epochs or tuning the optimiser or even adding more layers will  aid in the model's performance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Subclassing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"custom_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_1 (KerasLayer)  {'input_word_ids': (None  0         \n",
      "                             , 128),                             \n",
      "                              'input_type_ids': (None            \n",
      "                             , 128),                             \n",
      "                              'input_mask': (None, 12            \n",
      "                             8)}                                 \n",
      "                                                                 \n",
      " keras_layer (KerasLayer)    {'sequence_output': (Non  109482241 \n",
      "                             e, 128, 768),                       \n",
      "                              'pooled_output': (None,            \n",
      "                              768),                              \n",
      "                              'encoder_outputs': [(No            \n",
      "                             ne, 128, 768),                      \n",
      "                              (None, 128, 768),                  \n",
      "                              (None, 128, 768),                  \n",
      "                              (None, 128, 768),                  \n",
      "                              (None, 128, 768),                  \n",
      "                              (None, 128, 768),                  \n",
      "                              (None, 128, 768),                  \n",
      "                              (None, 128, 768),                  \n",
      "                              (None, 128, 768),                  \n",
      "                              (None, 128, 768),                  \n",
      "                              (None, 128, 768),                  \n",
      "                              (None, 128, 768)],                 \n",
      "                              'default': (None, 768)}            \n",
      "                                                                 \n",
      " intermediate_layer0 (Dense)  (None, 64)               49216     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 64)               256       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " intermediate_layer1 (Dense)  (None, 64)               4160      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64)               256       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,536,324\n",
      "Trainable params: 53,827\n",
      "Non-trainable params: 109,482,497\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Subclassing version static\n",
    "class CustomBertModel(tf.keras.Model):\n",
    "    def __init__(self,num_units,repetitions,**kwargs):\n",
    "        super(CustomBertModel,self).__init__(**kwargs)\n",
    "        self.bert_preprocess = bert_preprocess\n",
    "        self.bert_encoder = bert_encoder\n",
    "        self.intermediate_layers = []\n",
    "        \n",
    "        for i  in range(repetitions):\n",
    "            self.intermediate_layers.append(\n",
    "                tf.keras.layers.Dense(num_units,activation='relu',name=f\"intermediate_layer{i}\")\n",
    "            )\n",
    "\n",
    "            self.intermediate_layers.append(tf.keras.layers.BatchNormalization())\n",
    "            self.intermediate_layers.append(tf.keras.layers.Dropout(0.2))\n",
    "        \n",
    "        self.output_layer = tf.keras.layers.Dense(3,activation='softmax',name=\"output_layer\")\n",
    "\n",
    "\n",
    "    def call(self,inputs):\n",
    "        text_inputs = tf.keras.layers.Input(shape=(), dtype=tf.string,name='text')\n",
    "        preprocess = self.bert_preprocess(text_inputs)\n",
    "        outputs = self.bert_encoder(preprocess)\n",
    "        x = outputs['pooled_output']\n",
    "        for layer in self.intermediate_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return self.output_layer(x)\n",
    "\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "subclass_model1 = CustomBertModel(64,2)\n",
    "subclass_model1.compile(optimizer=optimise,\n",
    "            loss=loss,\n",
    "            metrics=['acc',precision,recall\n",
    "            ])\n",
    "\n",
    "subclass_model1.build(input_shape=[(None,),])  # Build the model to see the summary\n",
    "subclass_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text (InputLayer)           [(None,)]                 0         \n",
      "                                                                 \n",
      " custom_bert_model2 (CustomB  (None, 64)               109911105 \n",
      " ertModel2)                                                      \n",
      "                                                                 \n",
      " Output_layer (Dense)        (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,911,300\n",
      "Trainable params: 427,907\n",
      "Non-trainable params: 109,483,393\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Subclassing version flexible - not final output\n",
    "class CustomBertModel2(tf.keras.Model):\n",
    "    def __init__(self,num_units:list,repetitions,**kwargs):\n",
    "        super(CustomBertModel2,self).__init__(**kwargs)\n",
    "        self.repetitions = repetitions\n",
    "        self.num_units = num_units\n",
    "        self.bert_preprocess = bert_preprocess\n",
    "        self.bert_encoder = bert_encoder\n",
    "        self.intermediate_layers = self.build_intermediate_layer()\n",
    "\n",
    "    def build_intermediate_layer(self):\n",
    "        layers = []\n",
    "        for i in range(self.repetitions):\n",
    "            \n",
    "            layers.extend([\n",
    "                tf.keras.layers.Dense(self.num_units[i], activation=\"relu\",name=f\"intermediate_layer{i}\"),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.Dropout(0.2)\n",
    "            ])\n",
    "        \n",
    "        return layers\n",
    "\n",
    "\n",
    "    def call(self,inputs):\n",
    "        preprocess = self.bert_preprocess(inputs)\n",
    "        outputs = self.bert_encoder(preprocess)\n",
    "        x = outputs['pooled_output']\n",
    "        for layer in self.intermediate_layers:\n",
    "            x = layer(x)\n",
    "        \n",
    "        # return self.output_layer(x)\n",
    "        return x\n",
    "\n",
    "    # def build_graph(self, raw_shape):\n",
    "    #     x = tf.keras.layers.Input(shape=(raw_shape), \n",
    "    #                                      ragged=True)\n",
    "\n",
    "    #     return tf.keras.Model(inputs=[x], \n",
    "    #                           outputs=self.call(x))\n",
    "\n",
    "num_units = [512,64]\n",
    "reps = len(num_units)\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string,name='text')\n",
    "\n",
    "\n",
    "subclass_model2 = CustomBertModel2(num_units=num_units,repetitions=reps)(text_input)\n",
    "output = tf.keras.layers.Dense(3, name='Output_layer',activation=\"softmax\")(subclass_model2)\n",
    "model2 = tf.keras.Model(inputs=[text_input], outputs=[output])\n",
    "# print(subclass_model2.summary()) # Doesn't work\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer=optimise,\n",
    "            loss=loss,\n",
    "            metrics=['acc',precision,recall\n",
    "            ])\n",
    "# Model training\n",
    "tf.keras.backend.clear_session()\n",
    "bert_model_history = model2.fit(X_train,y_train,epochs=20,\n",
    "                        validation_split=.20,\n",
    "                        batch_size=16,\n",
    "                        # steps_per_epoch=5,\n",
    "                        callbacks=[callback,my_scheduler,\n",
    "                        peak_callback,my_timer])\n",
    "\n",
    "# This works when ran with the previous cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add block & Concatenate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddInputLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(AddInputLayer,self).__init__(**kwargs)\n",
    "    def call(self,inputs):\n",
    "        final_output, text_input = inputs\n",
    "        return final_output + text_input\n",
    "        # return tf.keras.layers.Add()([final_output,text_input])\n",
    "\n",
    "# https://stackoverflow.com/questions/72737550/why-tf-keras-layers-concatenate-adds-parameters-to-my-model\n",
    "class ConcatenateLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ConcatenateLayer,self).__init__(**kwargs)\n",
    "    def call(self,inputs):\n",
    "        return tf.concat(inputs,axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " text (InputLayer)           [(None,)]                 0         \n",
      "                                                                 \n",
      " custom_bert_model3_2 (Custo  (None, 64)               109980545 \n",
      " mBertModel3)                                                    \n",
      "                                                                 \n",
      " Output_layer (Dense)        (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 109,980,740\n",
      "Trainable params: 495,427\n",
      "Non-trainable params: 109,485,313\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Final: works with the next cells above and below.\n",
    "class CustomBertModel3(tf.keras.Model):\n",
    "    def __init__(self,num_units:list,repetitions,**kwargs):\n",
    "        super(CustomBertModel3,self).__init__(**kwargs)\n",
    "        self.repetitions = repetitions\n",
    "        self.num_units = num_units\n",
    "        self.bert_preprocess = bert_preprocess\n",
    "        self.bert_encoder = bert_encoder\n",
    "        self.intermediate_layers = self.build_intermediate_layer()\n",
    "        self.add_layer = AddInputLayer()\n",
    "        self.concat_layer = ConcatenateLayer()\n",
    "        self.dense1 = tf.keras.layers.Dense(64,activation=\"relu\",name=\"final_dense\")\n",
    "\n",
    "    def build_intermediate_layer(self):\n",
    "        layers = []\n",
    "        for i in range(self.repetitions):\n",
    "            \n",
    "            layers.extend([\n",
    "                tf.keras.layers.Dense(self.num_units[i], activation=\"relu\",name=f\"intermediate_layer{i}\"),\n",
    "                tf.keras.layers.BatchNormalization(),\n",
    "                tf.keras.layers.Dropout(0.2)\n",
    "            ])\n",
    "        \n",
    "        return layers\n",
    "\n",
    "\n",
    "    def call(self,inputs):\n",
    "        preprocess = self.bert_preprocess(inputs)\n",
    "        outputs1 = self.bert_encoder(preprocess)\n",
    "        outputs2 = outputs1['pooled_output']\n",
    "        for layer in self.intermediate_layers:\n",
    "            x = layer(outputs2)\n",
    "        x = self.add_layer([x,outputs2])\n",
    "        # x = self.concat_layer([x, outputs2])\n",
    "        \n",
    "        # return x\n",
    "        return self.dense1(x)\n",
    "\n",
    "num_units = [512,64]\n",
    "reps = len(num_units)\n",
    "\n",
    "\n",
    "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "subclass_model3 = CustomBertModel3(num_units=num_units, repetitions=reps)(text_input)\n",
    "output = tf.keras.layers.Dense(3, name='Output_layer', activation=\"softmax\")(subclass_model3)\n",
    "\n",
    "# Create the final model using tf.keras.Model\n",
    "model3 = tf.keras.Model(inputs=[text_input], outputs=[output])\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer=optimise,\n",
    "            loss=loss,\n",
    "            metrics=['acc',precision,recall\n",
    "            ])\n",
    "# Model training\n",
    "bert_model_history = model3.fit(X_train,y_train,epochs=20,\n",
    "                        validation_split=.20,\n",
    "                        batch_size=16,\n",
    "                        # steps_per_epoch=5,\n",
    "                        callbacks=[callback,my_scheduler,\n",
    "                        peak_callback,my_timer])\n",
    "\n",
    "# This works when ran with the previous cell"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 (conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0d3784fccdc90acbf957f8297e7e306d4c8b14c1a207bd5307d0795df9a8d77b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
